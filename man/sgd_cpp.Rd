% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{sgd_cpp}
\alias{sgd_cpp}
\title{Stochastic Gradient descent algorithm with different step size methods}
\usage{
sgd_cpp(
  paras,
  obj_fun,
  grad_fun,
  dat,
  step_size_method = as.character(c("fixed", "decreasing", "BB")),
  n = -1L,
  max_iter = 10000L,
  mini_batch_size = 1L,
  update_freq = 100L,
  weight = 1,
  step_size = 1e-04,
  diminishing_ratio = 0.01,
  r = 0.55,
  tol = 1e-04,
  burnin = 5000L,
  verbose = 1000L
)
}
\arguments{
\item{paras}{numeric vector}

\item{obj_fun}{objective function to be minimized}

\item{grad_fun}{gradient function}

\item{dat}{list object to pass other data to the objective function 
and the gradient of the objective functions}

\item{step_size_method}{indicate the methods to determine the step size}

\item{n}{total numbers of sub functions in the objective function}

\item{max_iter}{positive integer for maximum number of iterations}

\item{weight}{number between 0 and 1 to indicate the rate to smooth the gradient over iterations}

\item{step_size}{numeric scalar for the initial step size}

\item{diminishing_ratio}{the rate of decreasing the step size}

\item{tol}{tolerance for the stopping criterion}
}
\value{
a list of objects
}
\description{
Stochastic Gradient descent algorithm with different step size methods
}
\examples{
regdat <- simul_linear_reg(n = 1000, p = 5, pos_corr = 0.6)
regdat$lambda = 0.001
res <- sgd_cpp(paras=rep(0,length=ncol(regdat$X)),ridge_reg_loss_cpp,
grad_ridge_reg_loss_cpp,regdat,
step_size_method = "decreasing")

}
\author{
Jian Kang <jiankang@umich.edu>
}
